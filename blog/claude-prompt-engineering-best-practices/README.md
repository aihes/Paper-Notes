# Prompt Engineering 最佳实践：一份全面的实战指南

## 一句话总结 (TL;DR)

Prompt Engineering 的核心是通过清晰、明确的指令和上下文来引导 AI 模型，以获得高质量、符合预期的输出。它是一门涵盖了**从明确指令、提供上下文、使用示例，到利用思维链、提示链和格式控制等高级技巧的系统性学科**。掌握这些方法论，并通过不断的迭代测试，是高效利用现代大语言模型的关键。

---

## 1. 问题陈述：为何需要 Prompt Engineering？

在与大语言模型（LLM）互动时，用户普遍面临一个挑战：如何稳定、高效地让模型输出我们真正想要的内容？模糊的指令（如“给我写个报告”）常常导致泛泛而谈或不相关的结果，需要多次反复沟通才能达成目标。这不仅浪费时间，也极大地影响了 AI 的应用效率和可靠性。Prompt Engineering 正是为解决这一“沟通鸿沟”而生的“指令的艺术”。

## 2. 核心原则：Prompt是一门沟通的科学

**Prompt Engineering 是一门沟通的科学，而非玄学**。它是一套可以通过学习和实践掌握的结构化方法，其精髓在于将人类的意图，通过精心设计的指令（Prompt），准确无误地传达给 AI。

这些技巧可以分为三个层次，由浅入深：

1.  **核心技巧 (Core techniques)**：构成有效 AI 交互的基础，是日常应用中最常用、性价比最高的方法。
2.  **高级技巧 (Advanced techniques)**：适用于构建 Agent、处理复杂数据结构或多阶段任务的专业场景。
3.  **过时但仍有用的技巧 (Techniques you might have heard about)**：一些在早期模型中流行，但在现代模型中已非必需，但在特定情况下仍有价值的技巧。

---

## 3. 关键技术细节

### 3.1. 核心技巧：基础但最重要

这是获得高质量输出的基石，核心要点有五个：

#### 1. 明确与清晰 (Be explicit and clear)
直接告诉模型你想要什么，使用明确的动词。不要假设模型能猜到你的意图。

*   **原则**: “Tell, don't assume.” (告知，而非假设)
*   **反例**: "创建一个分析仪表盘"
*   **正例**: "**创建一个分析仪表盘。请包含尽可能多的相关功能和交互。超越基础功能，实现一个功能完备的版本。**"
*   **要点**:
    *   使用“分析”、“生成”、“创建”等行动指令。
    *   省略“你好”、“请帮我”等客套话，直奔主题。
    *   明确指出对质量和深度的期望。

#### 2. 提供上下文与动机 (Provide context and motivation)
解释你“为什么”需要这个结果，以及它的用途和受众。这能帮助模型更好地理解你的深层目标。

*   **原则**: "Explain the 'why'." (解释原因)
*   **反例**: "永远不要用项目符号列表。"
*   **正例**: "**我更喜欢自然的段落形式而不是项目符号，因为我发现流动的散文更容易阅读，更具对话感。对我这种非正式的学习风格来说，项目符号太正式了，像个清单。**"
*   **要点**: 解释原因后，模型不仅会遵守规则，还会在遇到类似决策时，举一反三，做出更符合你偏好的选择。

#### 3. 具体化 (Be specific)
提供明确的约束条件。

*   **原则**: "Constraints breed creativity and accuracy." (约束催生创造力与准确性)
*   **反例**: "为地中海饮食制定一个膳食计划。"
*   **正例**: "**为糖尿病前期管理设计一个地中海饮食计划。每日热量 1800 卡路里，重点使用低升糖指数的食物。列出早餐、午餐、晚餐和一份零食，并提供完整的营养成分明细。**"
*   **要点**: 约束条件越具体（饮食需求、预算、技术栈），输出结果越贴近实际需求。

#### 4. 善用示例 (Use examples)
当格式或风格难以用语言描述时，“展示而非告知”（Show, don't tell）是最好的方法。这就是所谓的“one-shot”或“few-shot” prompting。

*   **原则**: "Show, don't just tell." (展示，而非仅仅告知)
*   **正例 (文章摘要)**:
    ```
    这是一个我想要的摘要风格示例：
    文章: [关于AI法规的文章链接]
    摘要: 欧盟通过全面的AI法案，针对高风险系统。关键条款包括透明度要求和人类监督授权。2026年生效。

    现在，请用同样的风格总结这篇文章：[你的新文章链接]
    ```
*   **要点**: 现代模型（如 Claude 3）对示例中的细节极为敏感。请确保你的示例完美地体现了你想要的风格，同时不包含任何你希望避免的模式。

#### 5. 给予表达不确定性的许可 (Give permission to express uncertainty)
明确告诉模型“如果信息不足，请直接说明，不要猜测”。

*   **原则**: "Empower 'I don't know'." (赋予“我不知道”的权利)
*   **正例**: "**分析这份财务数据并找出趋势。如果数据不足以得出结论，请直接说明，不要进行推测。**"
*   **要点**: 这条简单的指令是抑制模型“幻觉”（hallucinations）最有效的方法之一，能显著提升输出结果的可靠性。

### 3.2. 高级技巧：处理复杂任务

#### 1. 预填充 AI 的回应 (Prefill the AI's response)
在 API 调用中，将 `assistant` 角色的消息预先填入一个起始符号（如 `{"`），可以强制模型以特定格式（如 JSON）开始和继续输出。

*   **场景**: 需要严格的 JSON、XML 或其他结构化数据输出时。
*   **API 示例**:
    ```python
    messages=[
        {"role": "user", "content": "从这个产品描述中提取名称和价格，以JSON格式输出。"},
        {"role": "assistant", "content": "{"}
    ]
    ```
*   **效果**: 模型会从 `{"` 后面继续写，确保了输出的纯净性，避免了 "这是您要的JSON..." 等前言。

#### 2. 思维链提示 (Chain of Thought - CoT)
要求模型在回答前“一步一步地思考”。这能显著提升复杂分析任务的准确性。

*   **场景**: 多步推理、数学计算、复杂分析。
*   **三种实现**:
    1.  **基础式**: 简单地在指令后加上“**Think step-by-step**”。
    2.  **引导式**: 为模型的思考过程提供具体的阶段划分，如：“**首先，分析... 其次，评估... 最后，总结...**”
    3.  **结构化 (最推荐)**：使用 XML 标签将思考过程和最终答案明确分开。
        ```
        在 <thinking> 标签中进行思考。首先，分析...然后...。最后，在 <email> 标签中撰写最终的邮件。
        ```
*   **注意**: Claude 的“扩展思考”功能在可用时是 CoT 的更好替代品，但手动 CoT 仍然非常重要。

#### 3. 提示链 (Prompt chaining)
将一个复杂的大任务，拆分成多个简单的小任务，每个任务对应一个独立的 Prompt。

*   **原则**: "Do one thing, and do it well." (一次只做一件事，并把它做好)
*   **示例 (研究报告)**:
    1.  **Prompt 1**: “总结这篇医学论文的方法、发现和临床意义。”
    2.  **Prompt 2**: “审查上述摘要的准确性、清晰度和完整性，并提供分级反馈。”
    3.  **Prompt 3**: “根据以下反馈，改进原始摘要：[第二步的反馈]”
*   **权衡**: 这种方法虽然增加了 API 调用的次数和延迟，但对于复杂任务，它带来的**准确性和可靠性提升**是巨大的。

### 3.3. 过时但仍有用的技巧

*   **XML 标签**：在早期模型中，使用 `<document>`、`<instructions>` 等标签来包裹和区分不同部分的内容很常用。虽然现代模型对自然语言的理解力更强，但在处理包含代码、数据、指令等极其复杂的混合 Prompt 时，XML 标签依然是确保边界清晰、避免混淆的有效手段。
*   **角色提示 (Role prompting)**：例如“你是一位资深财务分析师...”。对于现代模型，过度具体的角色设定（如“从不犯错的专家”）有时会限制模型的发挥。通常，更有效的方法是直接说明你需要的**分析视角**（如“从风险和长期增长的角度分析...”），而不是强行赋予一个角色。

---

## 4. 结论与最佳实践

*   **结论**: **最好的 Prompt，不是最长或最复杂的那个，而是能以最精简的结构，稳定可靠地达成你目标的那个。**
*   **迭代心法**: Prompt Engineering 不是一次性的行为，而是一个**迭代和测试**的循环。从简单的核心技巧开始，只有在遇到特定问题时才逐步引入更高级的技巧。
*   **避免过度设计**: 不要一次性使用所有技巧。如果一个简单的 Prompt 能解决问题，就不要复杂化。

## 5. 总结

Prompt Engineering 已经从一种“黑客秘籍”式的技巧，演变为一门可以被系统学习和掌握的、更加科学化的学科。随着模型能力越来越强，“如何与模型沟通”本身也变得越来越重要。**“上下文工程 (Context Engineering)”** 概念的出现，预示着未来的重点将不仅在于单个 Prompt 的设计，更在于如何构建和管理一个完整的、包含对话历史、外部文件和系统指令的上下文环境，以驱动 AI 完成更宏大的任务。

---

## 参考资料

*   本文内容主要思想和实践方法，可以参考 Claude 官方发布的最佳实践文章：[Best practices for prompt engineering](https://claude.com/blog/best-practices-for-prompt-engineering)
